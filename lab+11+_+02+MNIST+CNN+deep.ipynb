{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\\nTensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\\nTensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\\nTensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\\nTensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\\nTensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\\nTensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\\nTensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"add_1:0\", shape=(?, 10), dtype=float32)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.410797768\n",
      "Epoch: 0002 cost = 0.100139791\n",
      "Epoch: 0003 cost = 0.072943543\n",
      "Epoch: 0004 cost = 0.061372380\n",
      "Epoch: 0005 cost = 0.051351071\n",
      "Epoch: 0006 cost = 0.046807201\n",
      "Epoch: 0007 cost = 0.044628282\n",
      "Epoch: 0008 cost = 0.037558849\n",
      "Epoch: 0009 cost = 0.038178586\n",
      "Epoch: 0010 cost = 0.034444046\n",
      "Epoch: 0011 cost = 0.031689149\n",
      "Epoch: 0012 cost = 0.031378232\n",
      "Epoch: 0013 cost = 0.029226546\n",
      "Epoch: 0014 cost = 0.027679284\n",
      "Epoch: 0015 cost = 0.025163794\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAFTRJREFUeJzt3X+MZXV5x/H3U4ph2coQodnFSmDpYliNJZ2hS7ewSIUE\npQZtFJsLSq0SpWo1E2l1jelS0dRK7NBitzFI8Qf1JhhqBQR2AS0tWH444w/EpcgvQXC34MbB7LIV\n2G//uHfbmWGZPWfmnn3u3Hm/kptwz3nuPc+Xc/nwnXPPOTdKKUiScvxKdgOStJgZwpKUyBCWpESG\nsCQlMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEv1qdgMRcQhwGvAwsDO3G0nqiQOAI4GNpZSfzVbYWAhH\nxHuB84HlwPeAPyul3LWH0tOAf26qD0lKdDbw5dkKGgnhiPgj4NPAu4A7gVFgY0S8vJTy5IzyhwGu\nuOIKVq1aNW3F6OgoY2NjTbSYbpDHBoM9Pse2cO2r8W3evJm3vvWt0M232TQ1Ex4FPltK+SJARJwH\n/AHwDuBTM2p3AqxatYrh4eFpK4aGhp63bFAM8thgsMfn2BauhPHt9RBrz7+Yi4j9gRHg5t3LSudW\nbTcBa3q9PUlayJo4O+JQYD9g64zlW+kcH5YkdXmKmiQlauKY8JPAc8CyGcuXAVte6EWjo6MMDQ1N\nW3bEEUf0vLl+0Wq1slto1CCPz7EtXE2Mr91u0263py2bnJys/Ppo4pc1IuJ24I5Syge6zwN4BPj7\nUspFM2qHgfHx8fGB/kJA0uIxMTHByMgIwEgpZWK22qbOjvhb4PMRMc7/n6J2IPD5hrYnSQtSIyFc\nSrkyIg4FPkbnMMR3gdNKKU80sT1JWqgau2KulLIB2NDU+0vSIPDsCElKZAhLUiJDWJISGcKSlMgQ\nlqREhrAkJTKEJSmRISxJiQxhSUpkCEtSIkNYkhIZwpKUyBCWpESGsCQlMoQlKZEhLEmJDGFJSmQI\nS1IiQ1iSEhnCkpTIEJakRIawJCUyhCUpkSEsSYkMYUlKZAhLUiJDWJISGcKSlMgQlqREhrAkJTKE\nJSmRISxJiX41uwFpT7Zv31659qqrrqpc++yzz9bq49xzz61VX1UppXJtRFSuPeywwyrXjo+PV65d\nvnx55VrV40xYkhIZwpKUyBCWpESGsCQlMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEhnCkpTIEJakRD2/\nd0RErAfWz1h8bynlFb3elvLddtttlWvvuuuuyrWf+MQnKtdu27atcm1dde7b0A/vu2XLlsq199xz\nT+Va7x3RnKZu4PMD4BRg9yet3l1TJGmRaCqEny2lPNHQe0vSwGjqmPDREfFYRDwQEVdExOENbUeS\nFrQmQvh24O3AacB5wArg3yNiaQPbkqQFreeHI0opG6c8/UFE3An8GHgLcHmvtydJC1njv6xRSpmM\niPuAlbPVjY6OMjQ0NG1Zq9Wi1Wo12Z4kzUu73abdbk9bNjk5Wfn1jYdwRPwanQD+4mx1Y2NjDA8P\nN92OJPXUniaLExMTjIyMVHp9z48JR8RFEXFSRBwREb8HfBV4Bmjv5aWStOg0MRN+GfBl4BDgCeBW\n4HdLKT9rYFuStKA18cWcB3ElqSJ/8l7zcskll1Su/cpXvtJID0uWLKlce+aZZzbSA8Cb3vSmyrVn\nnXVW5drt27fPpR0tEN7AR5ISGcKSlMgQlqREhrAkJTKEJSmRISxJiQxhSUpkCEtSIkNYkhIZwpKU\nyMuWNS+XXXZZ5doLL7ywkR7233//yrVHHnlkIz1AvcuLDznkkEbeVwuPM2FJSmQIS1IiQ1iSEhnC\nkpTIEJakRIawJCUyhCUpkSEsSYkMYUlKZAhLUiIvW9a8LF26tHLt0Ucf3WAnzdi5c2fl2je/+c2V\nax955JG5tLNXJ5xwQuXa4447rpEeVI8zYUlKZAhLUiJDWJISGcKSlMgQlqREhrAkJTKEJSmRISxJ\niQxhSUpkCEtSIi9b1qLy7LPP1qq/9NJLK9du2rSpbjuVvOpVr6pce80111SuHRoamks76jFnwpKU\nyBCWpESGsCQlMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEhnCkpTIEJakRF62rL500003Va699957K9de\nffXVtfq4+eaba9U34f3vf3/lWi9FXnhqz4QjYm1EXB0Rj0XErog4Yw81H4uIxyNiR0TcGBEre9Ou\nJA2WuRyOWAp8F3gPUGaujIgPAe8D3gWsBrYDGyPiRfPoU5IGUu3DEaWUG4AbACIi9lDyAeDCUsq1\n3ZpzgK3AG4Er596qJA2enn4xFxErgOXA/x1IK6U8BdwBrOnltiRpEPT67IjldA5RbJ2xfGt3nSRp\nCk9Rk6REvT5FbQsQwDKmz4aXAd+Z7YWjo6PPO72m1WrRarV63KIk9U673abdbk9bNjk5Wfn1PQ3h\nUspDEbEFOAX4PkBEHAQcD/zDbK8dGxtjeHi4l+1IUuP2NFmcmJhgZGSk0utrh3BELAVW0pnxAhwV\nEccC20opjwIXAx+NiPuBh4ELgZ8AX6u7LUkadHOZCR8HfJPOF3AF+HR3+ReAd5RSPhURBwKfBQ4G\n/gN4XSnllz3oV5IGylzOE76FvXyhV0q5ALhgbi1pIXniiScq15544omVax944IHKtaU875qhgbJk\nyZLsFtQgz46QpESGsCQlMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEhnCkpTIEJakRIawJCXy15Y1L5s3\nb65ce//99zfYyeB65zvfWbl2165dlWvPPvvsubSjHnMmLEmJDGFJSmQIS1IiQ1iSEhnCkpTIEJak\nRIawJCUyhCUpkSEsSYkMYUlK5GXLmpfVq1dXrn300Ucr11566aWVa9euXVu59phjjqlcW9f4+Hjl\n2rPOOqty7Y4dOyrXvvvd765cW+ffxcjISOVa1eNMWJISGcKSlMgQlqREhrAkJTKEJSmRISxJiQxh\nSUpkCEtSIkNYkhIZwpKUyBCWpETeO0LzcsABB1SufelLX1q5dv369XNpJ1Wd8b3mNa+pXHvttddW\nrn366acr1/785z+vXKvmOBOWpESGsCQlMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEhnCkpTIEJakRIaw\nJCWqfdlyRKwF/hwYAQ4D3lhKuXrK+suBP57xshtKKafPp1FpkHzkIx+pXFvnsuU6tm3b1sj7qp65\nzISXAt8F3gOUF6i5HlgGLO8+WnPqTpIGXO2ZcCnlBuAGgIiIFyj7n1LKE/NpTJIWg6aOCZ8cEVsj\n4t6I2BARL2loO5K0oDVxK8vrgauAh4DfBP4auC4i1pRSXujwhSQtSj0P4VLKlVOe3hMRdwMPACcD\n3+z19iRpIWv8pu6llIci4klgJbOE8OjoKENDQ9OWtVotWi2/05PUv9rtNu12e9qyycnJyq9vPIQj\n4mXAIcBPZ6sbGxtjeHi46XYkqaf2NFmcmJhgZGSk0uvncp7wUjqz2t1nRhwVEccC27qP9XSOCW/p\n1v0NcB+wse62JGnQzWUmfBydwwql+/h0d/kX6Jw7/FvAOcDBwON0wvcvSynPzLtbSRowczlP+BZm\nP7XttXNvR5IWF39tWVqkJiYmKteeeeaZDXayuHkDH0lKZAhLUiJDWJISGcKSlMgQlqREhrAkJTKE\nJSmRISxJiQxhSUpkCEtSIi9blhJ8/etfz26BU089NbsF4UxYklIZwpKUyBCWpESGsCQlMoQlKZEh\nLEmJDGFJSmQIS1IiQ1iSEhnCkpRooC9bfuyxxyrXrlmzpnLtMcccU6uPj3/845VrV69eXeu91T/W\nrVtXufaiiy5qpIdDDz20cu2KFSsa6UH1OBOWpESGsCQlMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEhnC\nkpTIEJakRIawJCUa6MuWb7755sq1dS5xrlMLsN9++1Wuvf7662u9t+rZtWtXrfoLLrigcm2dS5FL\nKZVrly1bVrn2xhtvrFx71FFHVa5Vc5wJS1IiQ1iSEhnCkpTIEJakRIawJCUyhCUpkSEsSYkMYUlK\nZAhLUiJDWJIS1bpsOSLWAX8IHAM8DXwL+FAp5b4ZdR8DzgUOBm4D/rSUcn9POl6Atm3bVrl2x44d\nlWsPPPDAubSzIPzyl7+sXHv33XdXrv3whz9cq49vfOMbteqrqnMp8qZNmyrXvvKVr5xLO0pUdya8\nFrgEOB44Fdgf2BQRS3YXRMSHgPcB7wJWA9uBjRHxop50LEkDpNZMuJRy+tTnEfF24L+BEeDW7uIP\nABeWUq7t1pwDbAXeCFw5z34laaDM95jwwUABtgFExApgOfB/ty8rpTwF3AGsmee2JGngzDmEIyKA\ni4FbSyk/7C5eTieUt84o39pdJ0maYj73E94AvAI4oUe9SNKiM6cQjojPAKcDa0spP52yagsQwDKm\nz4aXAd+Z7T1HR0cZGhqatqzVatFqtebSoiTtE+12m3a7PW3Z5ORk5dfXDuFuAL8BeHUp5ZGp60op\nD0XEFuAU4Pvd+oPonE3xD7O979jYGMPDw3XbkaRUe5osTkxMMDIyUun1dc8T3gC0gDOA7RGx+2TH\nyVLKzu4/Xwx8NCLuBx4GLgR+AnytzrYkaTGoOxM+j84Xb/82Y/mfAF8EKKV8KiIOBD5L5+yJ/wBe\nV0qpfva9JC0Sdc8TrnQ2RSnlAuCCOfQjSYvKQP/acp1LQ+v8IvJzzz1Xq49vf/vblWtf//rXV649\n/PDDa/VR1Sc/+cnKtT/60Y8q11522WWVa+t8sXHNNddUrm3SscceW7n2S1/6UuVaL0UebN7AR5IS\nGcKSlMgQlqREhrAkJTKEJSmRISxJiQxhSUpkCEtSIkNYkhIZwpKUaKAvWz7ttNMq19b5Vd0PfvCD\ntfp48MEHK9fecssttd67CVdccUV2C4056KCDatW/7W1vq1w7NjZWubbOZfIabM6EJSmRISxJiQxh\nSUpkCEtSIkNYkhIZwpKUyBCWpESGsCQlMoQlKZEhLEmJBvqy5TpOPPHEyrV33HFHrff+xS9+Ubn2\nc5/7XOXa888/v1YfC8m6desq165atapy7UknnVSrj6Z+0VrazZmwJCUyhCUpkSEsSYkMYUlKZAhL\nUiJDWJISGcKSlMgQlqREhrAkJTKEJSmRISxJibx3xD7w4he/uHLt6OhoI7WS+pMzYUlKZAhLUiJD\nWJISGcKSlMgQlqREhrAkJTKEJSmRISxJiQxhSUpkCEtSolohHBHrIuLOiHgqIrZGxFcj4uUzai6P\niF0zHtf1tm1JGgx1Z8JrgUuA44FTgf2BTRGxZEbd9cAyYHn30Zpnn5I0kGrdwKeUcvrU5xHxduC/\ngRHg1imr/qeU8sS8u5OkATffY8IHAwXYNmP5yd3DFfdGxIaIeMk8tyNJA2nOt7KMiAAuBm4tpfxw\nyqrrgauAh4DfBP4auC4i1pRSynyalaRBM5/7CW8AXgGcMHVhKeXKKU/viYi7gQeAk4FvzmN7kjRw\n5hTCEfEZ4HRgbSnlp7PVllIeiogngZXMEsKjo6MMDQ1NW9ZqtWi1/E5PUv9qt9u02+1pyyYnJyu/\nPuoeIegG8BuAV5dSHqxQ/zLgx8AbSinX7mH9MDA+Pj7O8PBwrV4kqR9NTEwwMjICMFJKmZittu55\nwhuAs4GzgO0Rsaz7OKC7fmlEfCoijo+IIyLiFOBfgfuAjXMZjCQNsrpnR5wHHAT8G/D4lMdbuuuf\nA34L+BrwX8ClwF3ASaWUZ3rQryQNlLrnCc8a2qWUncBr59WRJC0i3jtCkhIZwpKUyBCWpESGsCQl\nMoQlKZEhLEmJDGFJSmQIS1IiQ1iSEhnCkpTIEJakRIawJCUyhCUpkSEsSYkMYUlKZAhLUqK+DuGZ\nP543SAZ5bDDY43NsC1c/js8QTjLIY4PBHp9jW7j6cXx9HcKSNOgMYUlKZAhLUqJav7bckAMANm/e\n/LwVk5OTTExM7POG9oVBHhsM9vgc28K1r8Y3Jc8O2FttlFKa7WZvDUScBfxzahOS1IyzSylfnq2g\nH0L4EOA04GFgZ2ozktQbBwBHAhtLKT+brTA9hCVpMfOLOUlKZAhLUiJDWJISGcKSlKgvQzgi3hsR\nD0XE0xFxe0T8TnZPvRAR6yNi14zHD7P7mouIWBsRV0fEY91xnLGHmo9FxOMRsSMiboyIlRm9zsXe\nxhcRl+9hX16X1W9VEbEuIu6MiKciYmtEfDUiXr6HugW576qMr9/2Xd+FcET8EfBpYD3w28D3gI0R\ncWhqY73zA2AZsLz7ODG3nTlbCnwXeA/wvFNsIuJDwPuAdwGrge109uOL9mWT8zDr+LquZ/q+bO2b\n1uZlLXAJcDxwKrA/sCkiluwuWOD7bq/j6+qffVdK6asHcDvwd1OeB/AT4C+ye+vB2NYDE9l9NDCu\nXcAZM5Y9DoxOeX4Q8DTwlux+ezS+y4F/ye6tB2M7tDu+Ewd03+1pfH217/pqJhwR+wMjwM27l5XO\nv7WbgDVZffXY0d0/cR+IiCsi4vDshnotIlbQmV1M3Y9PAXcwOPsR4OTun7z3RsSGiHhJdkNzcDCd\nmf42GMh9N218U/TNvuurEKbzf639gK0zlm+l88FY6G4H3k7nCsHzgBXAv0fE0symGrCczgd/UPcj\ndP6cPQd4DfAXwKuB6yIiUruqodvrxcCtpZTd300MzL57gfFBn+27friBz6JRStk45ekPIuJO4MfA\nW+j8iaQFopRy5ZSn90TE3cADwMnAN1Oaqm8D8ArghOxGGrLH8fXbvuu3mfCTwHN0DphPtQzYsu/b\naVYpZRK4D1gQ3zzXsIXOsfxFsR8BSikP0fn8Loh9GRGfAU4HTi6l/HTKqoHYd7OM73my911fhXAp\n5RlgHDhl97LunwinAN/K6qspEfFrdHb8rB+Shab7od7C9P14EJ1vrAduPwJExMuAQ1gA+7IbUG8A\nfr+U8sjUdYOw72Yb3wvUp+67fjwc8bfA5yNiHLgTGAUOBD6f2VQvRMRFwDV0DkH8BvBXwDNA//3w\n1V50j2OvpDNrAjgqIo4FtpVSHqVzLO6jEXE/nTvkXUjnLJevJbRb22zj6z7WA1fRCayVwN/Q+atm\n4/PfrX9ExAY6p2OdAWyPiN0z3slSyu67GC7Yfbe38XX3a3/tu+zTM17gtJL30Nn5TwP/CRyX3VOP\nxtWm82F+GngE+DKwIruvOY7l1XRO/XluxuOfptRcQOd0px10PuArs/vuxfjo3KbwBjr/Ee8EHgT+\nEfj17L4rjGtPY3oOOGdG3YLcd3sbXz/uO29lKUmJ+uqYsCQtNoawJCUyhCUpkSEsSYkMYUlKZAhL\nUiJDWJISGcKSlMgQlqREhrAkJTKEJSmRISxJif4Xe1IFCeGIC/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd388094c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
